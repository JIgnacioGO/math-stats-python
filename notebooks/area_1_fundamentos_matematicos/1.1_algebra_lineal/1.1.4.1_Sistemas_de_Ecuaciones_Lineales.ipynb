{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.4.1: Sistemas de Ecuaciones Lineales y Regresi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de Aprendizaje\n",
    "\n",
    "Al completar este notebook, ser√°s capaz de:\n",
    "\n",
    "- **Formular** un problema de regresi√≥n lineal simple y m√∫ltiple como un sistema de ecuaciones en la forma matricial $X\\vec{\\beta} = \\vec{y}$.\n",
    "- **Construir** la **matriz de dise√±o** $X$ (incluyendo el t√©rmino de intercepto) y el vector objetivo $\\vec{y}$ a partir de un dataset.\n",
    "- **Resolver** sistemas sobredeterminados usando la soluci√≥n de **m√≠nimos cuadrados** con `np.linalg.lstsq`.\n",
    "- **Interpretar** los coeficientes $\\vec{\\beta}$ resultantes en el contexto de un problema de datos.\n",
    "- **Comprender** y diagnosticar la **inestabilidad num√©rica** causada por la multicolinealidad usando el **n√∫mero de condici√≥n**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Celda de Configuraci√≥n (Oculta) ---\n",
    "%display latex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## ‚öôÔ∏è El Arsenal de Datasets: Nuestra Fuente de Ejercicios\n",
    "\n",
    "Este notebook es la aplicaci√≥n directa de los sistemas de ecuaciones al Machine Learning. Usaremos datasets para plantear problemas de regresi√≥n realistas y para explorar los desaf√≠os que surgen en la pr√°ctica, como la multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURACI√ìN DE DATASETS ===\n",
    "from src.data_generation.create_student_performance import create_student_performance_data\n",
    "from src.data_generation.create_business_data import create_business_data\n",
    "from src.data_generation.create_edge_cases import create_edge_cases\n",
    "\n",
    "# Configuraci√≥n centralizada de aleatoriedad para REPRODUCIBILIDAD\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# === Generaci√≥n de Datasets y Matrices para este Notebook ===\n",
    "\n",
    "# üí° CONTEXTO PEDAG√ìGICO: Hilo Conductor (Regresi√≥n Lineal Simple)\n",
    "# El problema de predecir la calificaci√≥n a partir de las horas de estudio es el ejemplo\n",
    "# can√≥nico para introducir la formulaci√≥n matricial de la regresi√≥n lineal.\n",
    "datos_estudiantes = create_student_performance_data(rng, simplified=True, n_samples=100)\n",
    "\n",
    "# üí° CONTEXTO PEDAG√ìGICO: Regresi√≥n M√∫ltiple\n",
    "# Para ir m√°s all√° de la l√≠nea recta, usaremos un problema de negocio donde predecimos\n",
    "# las ventas a partir de m√∫ltiples variables (precio, marketing), lo que requiere una matriz X m√°s ancha.\n",
    "datos_negocio = create_business_data(rng, n_samples=150)\n",
    "\n",
    "# üí° CONTEXTO PEDAG√ìGICO: Inestabilidad Num√©rica\n",
    "# Para entender por qu√© la multicolinealidad es un problema, generaremos un dataset donde\n",
    "# las features est√°n altamente correlacionadas. Esto nos permitir√° ver el efecto en el n√∫mero de condici√≥n.\n",
    "datos_multicolineales = create_edge_cases(rng, case_type='multicollinear', n_samples=100)\n",
    "\n",
    "print(\"Datasets generados y listos para usar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. De la Regresi√≥n a un Sistema de Ecuaciones\n",
    "\n",
    "En ciencia de datos, a menudo queremos modelar una variable objetivo $y$ en funci√≥n de una o m√°s variables predictoras (features) $x$. El modelo m√°s simple es la **regresi√≥n lineal**, que busca encontrar la l√≠nea (o hiperplano en m√°s dimensiones) que mejor se ajuste a los datos.\n",
    "\n",
    "La ecuaci√≥n para una **regresi√≥n lineal simple** es:\n",
    "$$ y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i $$\n",
    "Donde $\\beta_0$ es la ordenada en el origen (intercepto), $\\beta_1$ es la pendiente y $\\epsilon_i$ es el error (la distancia vertical del punto a la l√≠nea).\n",
    "\n",
    "Nuestro objetivo es encontrar los mejores coeficientes $\\vec{\\beta} = [\\beta_0, \\beta_1]$ que minimicen este error para todos los puntos de datos a la vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulando el Sistema $X\\vec{\\beta} = \\vec{y}$\n",
    "\n",
    "Para cada una de nuestras $m$ observaciones (estudiantes), podemos escribir una ecuaci√≥n. Si las apilamos, obtenemos un sistema sobredeterminado (m√°s ecuaciones que inc√≥gnitas) que podemos escribir en forma matricial:\n",
    "$$ \n",
    "\\underbrace{\\begin{pmatrix}\n",
    "1 & x_{1} \\\\\n",
    "1 & x_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "1 & x_{m}\n",
    "\\end{pmatrix}}_{X \\text{ (Matriz de Dise√±o, } m \\times 2)}\n",
    "\\underbrace{\\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\end{pmatrix}}_{\\vec{\\beta} \\text{ (Vector de Coeficientes, } 2 \\times 1)}\n",
    "\\approx\n",
    "\\underbrace{\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_{m}\n",
    "\\end{pmatrix}}_{\\vec{y} \\text{ (Vector Objetivo, } m \\times 1)}\n",
    "$$\n",
    "La columna de unos en la **matriz de dise√±o $X$** es un truco matem√°tico para que el coeficiente $\\beta_0$ (el intercepto) se pueda incluir limpiamente en la multiplicaci√≥n matricial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Demostrativo 1: Regresi√≥n Lineal Simple con el Hilo Conductor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATOS: Extraemos 'horas_estudio' como nuestra feature y 'calificacion_examen' como nuestro objetivo.\n",
    "X_feature = datos_estudiantes[['horas_estudio']].values\n",
    "y = datos_estudiantes['calificacion_examen'].values\n",
    "\n",
    "# 2. CONSTRUIR LA MATRIZ DE DISE√ëO X: A√±adimos la columna de unos para el intercepto.\n",
    "# np.c_ es una forma conveniente de concatenar columnas.\n",
    "X = np.c_[np.ones(X_feature.shape[0]), X_feature]\n",
    "\n",
    "print(\"Primeras 5 filas de la Matriz de Dise√±o X:\")\n",
    "print(X[:5])\n",
    "print(f\"\\nForma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "\n",
    "# 3. RESOLVER EL SISTEMA: Usamos M√≠nimos Cuadrados para encontrar la mejor soluci√≥n aproximada.\n",
    "# np.linalg.lstsq encuentra el beta que minimiza ||X_beta - y||^2\n",
    "beta, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "beta_0, beta_1 = beta\n",
    "\n",
    "# 4. INTERPRETACI√ìN Y VISUALIZACI√ìN\n",
    "print(f\"\\nCoeficientes encontrados:\")\n",
    "print(f\"  Œ≤‚ÇÄ (intercepto): {beta_0:.2f} -> Calificaci√≥n esperada con 0 horas de estudio.\")\n",
    "print(f\"  Œ≤‚ÇÅ (pendiente):   {beta_1:.2f} -> Puntos adicionales por cada hora de estudio.\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_feature, y, alpha=0.7, label='Datos Originales')\n",
    "plt.plot(X_feature, X @ beta, color='red', linewidth=3, label='L√≠nea de Regresi√≥n de M√≠nimos Cuadrados')\n",
    "plt.title('Regresi√≥n Lineal: Calificaci√≥n vs. Horas de Estudio')\n",
    "plt.xlabel('Horas de Estudio'); plt.ylabel('Calificaci√≥n del Examen')\n",
    "plt.legend(); plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extendiendo a Regresi√≥n M√∫ltiple\n",
    "\n",
    "La belleza del enfoque matricial es que se extiende sin esfuerzo a m√°s dimensiones. Si queremos predecir $y$ a partir de $n$ features, la ecuaci√≥n se convierte en:\n",
    "$$ y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_n x_{in} $$\n",
    "La √∫nica diferencia es que nuestra matriz de dise√±o $X$ ahora tiene m√°s columnas, una por cada feature (m√°s la columna de unos del intercepto). El vector $\\vec{\\beta}$ tambi√©n crece, pero el m√©todo de soluci√≥n `np.linalg.lstsq` sigue funcionando exactamente igual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Demostrativo 2: Regresi√≥n M√∫ltiple con Datos de Negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATOS: Predecir 'ventas_mensuales' a partir de 'precio' y 'gasto_marketing'.\n",
    "features = datos_negocio[['precio', 'gasto_marketing']].values\n",
    "y = datos_negocio['ventas_mensuales'].values\n",
    "\n",
    "# 2. CONSTRUIR MATRIZ DE DISE√ëO X: Ahora tendr√° 3 columnas (intercepto, precio, marketing).\n",
    "X = np.c_[np.ones(features.shape[0]), features]\n",
    "\n",
    "print(\"Primeras 5 filas de la Matriz de Dise√±o X (m√∫ltiple):\")\n",
    "print(np.round(X[:5], 2))\n",
    "print(f\"\\nForma de X: {X.shape}\")\n",
    "\n",
    "# 3. RESOLVER EL SISTEMA\n",
    "beta, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "beta_0, beta_1, beta_2 = beta\n",
    "\n",
    "# 4. INTERPRETACI√ìN\n",
    "print(f\"\\nCoeficientes encontrados:\")\n",
    "print(f\"  Œ≤‚ÇÄ (base): {beta_0:.2f} -> Ventas base sin precio ni marketing.\")\n",
    "print(f\"  Œ≤‚ÇÅ (precio): {beta_1:.2f} -> Cambio en ventas por cada unidad de aumento en el precio.\")\n",
    "print(f\"  Œ≤‚ÇÇ (marketing): {beta_2:.2f} -> Cambio en ventas por cada unidad de aumento en marketing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estabilidad Num√©rica y N√∫mero de Condici√≥n\n",
    "\n",
    "Un problema grave surge cuando las columnas de $X$ son muy similares (multicolinealidad). Esto hace que la matriz $(X^T X)$ (que `lstsq` resuelve internamente) est√© mal condicionada, casi singular. La soluci√≥n $\\vec{\\beta}$ se vuelve muy sensible a peque√±os cambios en los datos, es decir, **inestable** y poco fiable.\n",
    "\n",
    "El **n√∫mero de condici√≥n** (`np.linalg.cond`) mide esta sensibilidad. \n",
    "- Un n√∫mero **peque√±o** (cercano a 1) es **bueno** (matriz bien condicionada).\n",
    "- Un n√∫mero **muy grande** (e.g., > 1000) es una **se√±al de alerta** de multicolinealidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Demostrativo 3: El Peligro de la Multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATOS: Usamos el dataset donde x2 y x3 dependen de x1.\n",
    "X_mal_condicionado = datos_multicolineales[['x1', 'x2', 'x3']].values\n",
    "X_bien_condicionado = datos_estudiantes[['horas_estudio', 'calificacion_previa']].values # Del notebook anterior\n",
    "\n",
    "# 2. APLICACI√ìN: Calculamos el n√∫mero de condici√≥n.\n",
    "cond_mal = np.linalg.cond(X_mal_condicionado)\n",
    "cond_bien = np.linalg.cond(X_bien_condicionado)\n",
    "\n",
    "# 3. INTERPRETACI√ìN\n",
    "print(f\"N√∫mero de Condici√≥n (Features Correlacionadas): {cond_mal:,.2f}\")\n",
    "print(f\"N√∫mero de Condici√≥n (Features Independientes): {cond_bien:.2f}\")\n",
    "print(\"\\nüî¥ ¬°Alerta! Un n√∫mero de condici√≥n tan alto indica que la soluci√≥n de regresi√≥n con estos datos no ser√° fiable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Ejercicios Guiados con Scaffolding (8+)\n",
    "Rellena las partes marcadas con `# COMPLETAR` para afianzar tu comprensi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 1: Construir la Matriz de Dise√±o X ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS: Un array de NumPy con una sola feature.\n",
    "feature_x = np.array([5, 8, 12, 15])\n",
    "\n",
    "# TODO 1: Crea un vector de unos con la misma cantidad de filas que feature_x.\n",
    "intercepto = # COMPLETAR\n",
    "\n",
    "# TODO 2: Apila la columna de intercepto y la de feature_x para crear la matriz de dise√±o X.\n",
    "# PISTA: Usa np.c_[col1, col2]\n",
    "X = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "X_esperada = np.array([[1, 5], [1, 8], [1, 12], [1, 15]])\n",
    "assert X.shape == (4, 2)\n",
    "assert np.allclose(X, X_esperada)\n",
    "print(\"‚úÖ ¬°Matriz de dise√±o construida correctamente!\")\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 2: Resolver un Sistema Simple con M√≠nimos Cuadrados ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS: La matriz X del ejercicio anterior y un vector objetivo y.\n",
    "X = np.array([[1, 5], [1, 8], [1, 12], [1, 15]])\n",
    "y = np.array([12, 18, 25, 30])\n",
    "\n",
    "# TODO: Usa np.linalg.lstsq para encontrar el vector de coeficientes beta.\n",
    "# PISTA: La funci√≥n devuelve varias cosas, pero solo necesitas la primera.\n",
    "beta, _, _, _ = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "assert beta.shape == (2,)\n",
    "assert np.isclose(beta[0], 2.44) and np.isclose(beta[1], 1.84)\n",
    "print(\"‚úÖ ¬°Sistema resuelto correctamente!\")\n",
    "print(f\"Œ≤‚ÇÄ (intercepto) = {beta[0]:.2f}\")\n",
    "print(f\"Œ≤‚ÇÅ (pendiente) = {beta[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 3: Regresi√≥n M√∫ltiple con el Hilo Conductor ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS: Usaremos la versi√≥n completa de datos_estudiantes.\n",
    "datos_full = create_student_performance_data(rng, n_samples=50)\n",
    "features = datos_full[['horas_estudio', 'calificacion_previa']].values\n",
    "y = datos_full['calificacion_examen'].values\n",
    "\n",
    "# TODO 1: Construye la matriz de dise√±o X para este problema de regresi√≥n m√∫ltiple.\n",
    "# PISTA: No olvides la columna de unos para el intercepto.\n",
    "X = # COMPLETAR\n",
    "\n",
    "# TODO 2: Resuelve el sistema para encontrar los tres coeficientes beta.\n",
    "beta, _, _, _ = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "assert X.shape == (50, 3)\n",
    "assert beta.shape == (3,)\n",
    "print(\"‚úÖ ¬°Regresi√≥n m√∫ltiple completada!\")\n",
    "print(f\"Œ≤‚ÇÄ (Intercepto): {beta[0]:.2f}\")\n",
    "print(f\"Œ≤‚ÇÅ (Horas Estudio): {beta[1]:.2f}\")\n",
    "print(f\"Œ≤‚ÇÇ (Calif Previa): {beta[2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 4: Calcular el N√∫mero de Condici√≥n ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS: La matriz X del ejercicio anterior y la matriz de datos multicolineales.\n",
    "X_estudiantes = np.c_[np.ones(features.shape[0]), features]\n",
    "X_multi = datos_multicolineales[['x1', 'x2', 'x3']].values\n",
    "\n",
    "# TODO 1: Calcula el n√∫mero de condici√≥n de la matriz de estudiantes.\n",
    "# PISTA: Usa np.linalg.cond().\n",
    "cond_estudiantes = # COMPLETAR\n",
    "\n",
    "# TODO 2: Calcula el n√∫mero de condici√≥n de la matriz multicolineal.\n",
    "cond_multi = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "assert cond_estudiantes < 1000 # Esperamos que est√© bien condicionada\n",
    "assert cond_multi > 10000 # Esperamos que est√© mal condicionada\n",
    "print(\"‚úÖ ¬°C√°lculos correctos!\")\n",
    "print(f\"N√∫mero de condici√≥n (Estudiantes): {cond_estudiantes:.2f} (Estable)\")\n",
    "print(f\"N√∫mero de condici√≥n (Multicolineal): {cond_multi:,.2f} (Inestable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# 5. Banco de Ejercicios Pr√°cticos (30+)\n",
    "Ahora te toca a ti. Resuelve estos ejercicios para consolidar tu conocimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte A: Sistemas Cuadrados y Estabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1 (üü¢ F√°cil):** Resuelve el sistema 3x3: $x+y+z=6, 2y+5z=-4, 2x+5y-z=27$ usando `np.linalg.solve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2 (üü¢ F√°cil):** Calcula el n√∫mero de condici√≥n de la matriz del ejercicio A1. ¬øConsideras que es una matriz estable para resolver?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3 (üü° Medio):** Genera una matriz singular 3x3. Intenta resolver un sistema $A\\vec{x} = \\vec{b}$ con ella. ¬øQu√© ocurre? ¬øPor qu√©?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B: Regresi√≥n Lineal Simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B1 (üü¢ F√°cil):** Tienes 3 puntos: (1,2), (2,3), (3,5). Construye la matriz de dise√±o $X$ y el vector $\\vec{y}$ para un modelo de regresi√≥n lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B2 (üü¢ F√°cil):** Resuelve el sistema del ejercicio B1 usando `np.linalg.lstsq` para encontrar la l√≠nea de mejor ajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B3 (üü° Medio):** Toma una muestra aleatoria de 50 estudiantes de `datos_estudiantes`. Repite el proceso de regresi√≥n lineal. Compara los coeficientes $\\beta_0, \\beta_1$ obtenidos con los del ejemplo demostrativo. ¬øSon muy diferentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B4 (üü° Medio):** Usando el modelo que entrenaste en B3, ¬øqu√© calificaci√≥n predecir√≠as para un estudiante que estudi√≥ 15 horas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B5 (üî¥ Reto):** Ajusta un modelo de regresi√≥n para `datos_negocio` que prediga `ventas_mensuales` bas√°ndose √∫nicamente en `precio`. Visualiza los datos y la l√≠nea de regresi√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte C: Regresi√≥n M√∫ltiple y Retos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C1 (üü° Medio):** Construye la matriz de dise√±o y el vector objetivo para predecir `calificacion_examen` a partir de `horas_estudio` y `asistencia_porcentaje` del dataset completo de estudiantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C2 (üü° Medio):** Resuelve el sistema del ejercicio C1 y reporta los tres coeficientes $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C3 (üî¥ Reto):** Regresi√≥n Polin√≥mica. Para ajustar una par√°bola ($y = \\beta_0 + \\beta_1 x + \\beta_2 x^2$), la matriz de dise√±o necesita una columna para $x^2$. Toma `datos_estudiantes`, construye una matriz $X$ con las columnas `[1, horas, horas^2]` y resuelve para los tres $\\beta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C4 (üî¥ Reto):** Visualiza el ajuste parab√≥lico del ejercicio C3 sobre el scatter plot de los datos de estudiantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C5 (üî¥ Reto Conceptual):** ¬øPor qu√© una regresi√≥n polin√≥mica como la del ejercicio C3 sigue consider√°ndose un problema de *√°lgebra lineal* y se puede resolver con `lstsq`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Mini-Quiz de Autoevaluaci√≥n\n",
    "\n",
    "*Responde estas preguntas para verificar tu comprensi√≥n.*\n",
    "\n",
    "1. ¬øPor qu√© `np.linalg.solve` no funciona para la mayor√≠a de los problemas de regresi√≥n lineal del mundo real?\n",
    "2. En la matriz de dise√±o $X$ para $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$, ¬øqu√© representa la primera columna de unos?\n",
    "3. Un n√∫mero de condici√≥n muy alto en la matriz de dise√±o $X$ es un s√≠ntoma de... (completa la palabra).\n",
    "4. Si tienes $m$ observaciones y $n$ features (incluyendo el intercepto), ¬øcu√°l es la forma de la matriz de dise√±o $X$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "¬°Felicidades! Has implementado un algoritmo de Machine Learning desde cero, conectando directamente la teor√≠a de sistemas de ecuaciones con una aplicaci√≥n pr√°ctica y fundamental.\n",
    "\n",
    "- En el siguiente notebook, **`1.1.4.2_Proyecciones_y_Minimos_Cuadrados_OLS`**, profundizaremos en la **geometr√≠a** detr√°s de la soluci√≥n de m√≠nimos cuadrados. Descubriremos c√≥mo el concepto de **proyecci√≥n ortogonal** nos da esa 'mejor soluci√≥n aproximada' y derivaremos formalmente la famosa ecuaci√≥n normal $X^T X \\vec{\\beta} = X^T \\vec{y}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.x",
   "language": "sagemath",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
