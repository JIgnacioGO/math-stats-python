{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.4.3: Ortogonalizaci√≥n y Estabilidad Num√©rica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos de Aprendizaje\n",
    "\n",
    "Al completar este notebook, ser√°s capaz de:\n",
    "\n",
    "- **Diagnosticar** la inestabilidad de una matriz usando el **N√∫mero de Condici√≥n**.\n",
    "- **Entender** por qu√© las **bases ortonormales** son el \"santo grial\" para la estabilidad num√©rica en problemas de m√≠nimos cuadrados.\n",
    "- **Aplicar** el proceso de **Ortogonalizaci√≥n de Gram-Schmidt** para crear una base ortonormal a partir de una base cualquiera.\n",
    "- **Utilizar** la **Descomposici√≥n QR** como la encarnaci√≥n computacionalmente eficiente de Gram-Schmidt.\n",
    "- **Resolver** problemas de M√≠nimos Cuadrados de forma robusta usando la Descomposici√≥n QR y comparar su estabilidad con el m√©todo de las Ecuaciones Normales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# --- Celda de Configuraci√≥n (Oculta) ---\n",
    "%display latex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def plot_gram_schmidt(v1, v2):\n",
    "    proj_v2_on_v1 = (v2.dot(v1) / v1.dot(v1)) * v1\n",
    "    u2 = v2 - proj_v2_on_v1\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    # Vectores originales\n",
    "    plt.quiver(0, 0, v1[0], v1[1], angles='xy', scale_units='xy', scale=1, color='#0072B2', width=0.015, label='v1 (base original)')\n",
    "    plt.quiver(0, 0, v2[0], v2[1], angles='xy', scale_units='xy', scale=1, color='#D55E00', width=0.015, label='v2 (base original)')\n",
    "    # Proceso\n",
    "    plt.quiver(0, 0, proj_v2_on_v1[0], proj_v2_on_v1[1], angles='xy', scale_units='xy', scale=1, color='gray', linestyle='--', label='proy_v1(v2)')\n",
    "    plt.quiver(proj_v2_on_v1[0], proj_v2_on_v1[1], u2[0], u2[1], angles='xy', scale_units='xy', scale=1, color='#009E73', width=0.015, label='u2 (componente ortogonal)')\n",
    "    \n",
    "    limit = np.max(np.abs(np.vstack((v1, v2, u2)))) * 1.2\n",
    "    plt.xlim(-limit, limit); plt.ylim(-limit, limit)\n",
    "    plt.grid(True); plt.legend(); plt.title('Visualizaci√≥n del Proceso de Gram-Schmidt')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## ‚öôÔ∏è El Arsenal de Datasets: Nuestra Fuente de Ejercicios\n",
    "\n",
    "La estabilidad num√©rica es un problema del mundo real. Para estudiarlo, necesitamos datasets que imiten los problemas que encontramos en la pr√°ctica, como la multicolinealidad. Tambi√©n usaremos vectores simples para visualizar la geometr√≠a de la ortogonalizaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURACI√ìN DE DATASETS ===\n",
    "from src.data_generation.create_student_performance import create_student_performance_data\n",
    "from src.data_generation.create_edge_cases import create_edge_cases\n",
    "\n",
    "# Configuraci√≥n centralizada de aleatoriedad para REPRODUCIBILIDAD\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "# === Generaci√≥n de Datasets y Matrices para este Notebook ===\n",
    "\n",
    "# üí° CONTEXTO PEDAG√ìGICO: Hilo Conductor (Regresi√≥n Robusta)\n",
    "# Usaremos el dataset de estudiantes para comparar la soluci√≥n de OLS obtenida con las\n",
    "# Ecuaciones Normales vs. la obtenida con la Descomposici√≥n QR, demostrando que en\n",
    "# casos bien condicionados, ambas coinciden.\n",
    "datos_estudiantes = create_student_performance_data(rng, simplified=True, n_samples=100)\n",
    "\n",
    "# üí° CONTEXTO PEDAG√ìGICO: El Caso Problema (Multicolinealidad)\n",
    "# La mejor forma de apreciar la estabilidad de QR es usarlo donde las Ecuaciones Normales\n",
    "# sufren. Este dataset con alta multicolinealidad ser√° nuestro campo de pruebas.\n",
    "datos_multicolineales = create_edge_cases(rng, case_type='multicollinear', n_samples=100)\n",
    "\n",
    "# üí° CONTEXTO PEDAG√ìGICO: Vectores para Geometr√≠a\n",
    "# Para visualizar Gram-Schmidt, necesitamos vectores que NO sean ortogonales, para que\n",
    "# el algoritmo tenga algo que corregir.\n",
    "v1 = np.array([3, 1])\n",
    "v2 = np.array([2, 2])\n",
    "\n",
    "print(\"Datasets y vectores generados y listos para usar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. El Problema: Cuando las Ecuaciones Normales son Inestables\n",
    "\n",
    "En el notebook anterior, derivamos las Ecuaciones Normales $X^T X \\hat{\\beta} = X^T \\vec{y}$. Esta f√≥rmula es te√≥ricamente correcta, pero tiene un tal√≥n de Aquiles num√©rico: la matriz $X^T X$.\n",
    "\n",
    "Si las columnas de $X$ son casi linealmente dependientes (es decir, hay **multicolinealidad**), la matriz $X^T X$ se vuelve **mal condicionada**. Esto significa que es muy sensible a peque√±os errores de redondeo en los c√°lculos de punto flotante, y la soluci√≥n $\\hat{\\beta}$ puede ser muy imprecisa.\n",
    "\n",
    "#### Diagn√≥stico: El N√∫mero de Condici√≥n\n",
    "El **N√∫mero de Condici√≥n** de una matriz, `np.linalg.cond(A)`, mide esta sensibilidad. Un n√∫mero cercano a 1 es ideal (como en una matriz ortogonal). Un n√∫mero muy grande (e.g., > 1,000) es una bandera roja üö© de inestabilidad.\n",
    "\n",
    "**Regla Clave:** `cond(X·µÄX) = cond(X)¬≤`. Formar la matriz $X^T X$ **eleva al cuadrado el n√∫mero de condici√≥n**, empeorando dr√°sticamente la estabilidad del problema. Por esto, los m√©todos modernos evitan formar $X^T X$ expl√≠citamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Demostrativo 1: El N√∫mero de Condici√≥n Explota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATOS: Usamos el dataset con multicolinealidad, donde x2 y x3 dependen de x1.\n",
    "X_mal_condicionado = datos_multicolineales[['x1', 'x2', 'x3']].values\n",
    "X_bien_condicionado = datos_estudiantes[['horas_estudio', 'calificacion_examen']].values\n",
    "\n",
    "# 2. APLICACI√ìN: Comparamos los n√∫meros de condici√≥n.\n",
    "cond_X_bien = np.linalg.cond(X_bien_condicionado)\n",
    "cond_XTX_bien = np.linalg.cond(X_bien_condicionado.T @ X_bien_condicionado)\n",
    "\n",
    "cond_X_mal = np.linalg.cond(X_mal_condicionado)\n",
    "cond_XTX_mal = np.linalg.cond(X_mal_condicionado.T @ X_mal_condicionado)\n",
    "\n",
    "# 3. INTERPRETACI√ìN\n",
    "print(\"--- Caso Bien Condicionado ---\")\n",
    "print(f\"N√∫mero de Condici√≥n de X: {cond_X_bien:.2f}\")\n",
    "print(f\"N√∫mero de Condici√≥n de X·µÄX: {cond_XTX_bien:.2f}\")\n",
    "\n",
    "print(\"\\n--- Caso Mal Condicionado (Multicolinealidad) ---\")\n",
    "print(f\"N√∫mero de Condici√≥n de X: {cond_X_mal:,.2f}\")\n",
    "print(f\"N√∫mero de Condici√≥n de X·µÄX: {cond_XTX_mal:,.2f} (¬°Inmanejablemente alto!)\")\n",
    "\n",
    "print(f\"\\nObserva que {cond_X_mal**2:,.2f} es aproximadamente igual a {cond_XTX_mal:,.2f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. La Soluci√≥n: Ortogonalizaci√≥n\n",
    "\n",
    "El problema es que las columnas de $X$ \"se parecen\" entre s√≠. La soluci√≥n es encontrar una **base ortonormal** para el espacio columna de $X$. Una base ortonormal est√° compuesta por vectores que son:\n",
    "1.  **Ortogonales:** Todos son perpendiculares entre s√≠ (producto punto es cero).\n",
    "2.  **Normales:** Todos tienen longitud 1 (norma L2 es uno).\n",
    "\n",
    "Si pudi√©ramos reemplazar nuestra matriz $X$ por una matriz $Q$ con columnas ortonormales, las Ecuaciones Normales se simplificar√≠an a $I \\hat{\\beta} = Q^T \\vec{y}$, una soluci√≥n trivial y perfectamente estable.\n",
    "\n",
    "### El Algoritmo: Ortogonalizaci√≥n de Gram-Schmidt\n",
    "Este es el algoritmo cl√°sico para construir una base ortogonal $\\{\\vec{u_1}, \\vec{u_2}, \\dots\\}$ a partir de una base cualquiera $\\{\\vec{v_1}, \\vec{v_2}, \\dots\\}$.\n",
    "- **Paso 1:** $\\vec{u_1} = \\vec{v_1}$\n",
    "- **Paso 2:** Se toma $\\vec{v_2}$ y se le resta su proyecci√≥n sobre $\\vec{u_1}$. Lo que queda es ortogonal a $\\vec{u_1}$.\n",
    "  $$ \\vec{u_2} = \\vec{v_2} - \\text{proj}_{\\vec{u_1}}(\\vec{v_2}) $$\n",
    "- **Paso 3 (y siguientes):** Para $\\vec{v_k}$, se le restan sus proyecciones sobre todos los vectores ortogonales ya encontrados ($\\{\\vec{u_1}, \\dots, \\vec{u_{k-1}}\\}$).\n",
    "- **Normalizaci√≥n Final:** Se divide cada vector $\\vec{u_i}$ por su norma para obtener una base ortonormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Demostrativo 2: Visualizaci√≥n de Gram-Schmidt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATOS: Dos vectores linealmente independientes pero no ortogonales.\n",
    "v1 = np.array([3, 1])\n",
    "v2 = np.array([2, 2])\n",
    "print(f\"Producto punto original (v1¬∑v2): {v1 @ v2} (No es cero)\")\n",
    "\n",
    "# 2. APLICACI√ìN: Aplicamos el proceso\n",
    "u1 = v1\n",
    "proj_v2_on_u1 = (v2 @ u1) / (u1 @ u1) * u1\n",
    "u2 = v2 - proj_v2_on_u1\n",
    "\n",
    "# 3. INTERPRETACI√ìN Y VERIFICACI√ìN\n",
    "print(f\"Nueva base ortogonal: u1={np.round(u1, 2)}, u2={np.round(u2, 2)}\")\n",
    "print(f\"Producto punto nuevo (u1¬∑u2): {u1 @ u2:.10f} (Es cero)\")\n",
    "\n",
    "# 4. VISUALIZACI√ìN\n",
    "plot_gram_schmidt(v1, v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. La Herramienta Pr√°ctica: Descomposici√≥n QR\n",
    "\n",
    "En la pr√°ctica, no implementamos Gram-Schmidt a mano (es num√©ricamente inestable para muchas columnas). Usamos la **Descomposici√≥n QR**, que es la encarnaci√≥n de este proceso, implementada de forma robusta. Descompone cualquier matriz $A$ de $m \\times n$ en el producto:\n",
    "$$ A = QR $$\n",
    "- **$Q$**: Una matriz $m \\times n$ con **columnas ortonormales** que forman una base para el Espacio Columna de A.\n",
    "- **$R$**: Una **matriz triangular superior** $n \\times n$ que \"registra\" c√≥mo se combinaron los vectores de Q para reconstruir A.\n",
    "\n",
    "### Resolviendo M√≠nimos Cuadrados con QR\n",
    "Sustituimos $X=QR$ en el problema de m√≠nimos cuadrados $X\\vec{\\beta} = \\vec{y}$:\n",
    "$$ QR\\vec{\\beta} = \\vec{y} $$\n",
    "Multiplicamos por $Q^T$. Como $Q^T Q = I$, obtenemos:\n",
    "$$ R\\hat{\\beta} = Q^T\\vec{y} $$\n",
    "Como R es triangular, este sistema es muy f√°cil y **num√©ricamente estable** de resolver para $\\hat{\\beta}$ usando un m√©todo llamado \"sustituci√≥n hacia atr√°s\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo Demostrativo 3: Comparando OLS: Ecuaciones Normales vs. Descomposici√≥n QR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATOS: Usaremos el dataset con alta multicolinealidad.\n",
    "X = datos_multicolineales[['x1', 'x2', 'x3']].values\n",
    "y = datos_multicolineales['y'].values\n",
    "\n",
    "# 2. APLICACI√ìN: Resolvemos de ambas formas.\n",
    "\n",
    "# M√©todo 1: Ecuaciones Normales (Potencialmente Inestable)\n",
    "XTX = X.T @ X\n",
    "XTy = X.T @ y\n",
    "try:\n",
    "    beta_norm = np.linalg.solve(XTX, XTy)\n",
    "except np.linalg.LinAlgError:\n",
    "    beta_norm = [np.nan, np.nan, np.nan] # Fall√≥\n",
    "\n",
    "# M√©todo 2: Descomposici√≥n QR (Robusto)\n",
    "Q, R = np.linalg.qr(X)\n",
    "QTy = Q.T @ y\n",
    "beta_qr = np.linalg.solve(R, QTy)\n",
    "\n",
    "# 3. INTERPRETACI√ìN Y COMPARACI√ìN\n",
    "print(f\"N√∫mero de Condici√≥n de X·µÄX: {np.linalg.cond(XTX):,.2f}\")\n",
    "print(f\"\\nSoluci√≥n con Ecuaciones Normales: {np.round(beta_norm, 4)}\")\n",
    "print(f\"Soluci√≥n con Descomposici√≥n QR: {np.round(beta_qr, 4)}\")\n",
    "print(\"\\nConclusi√≥n: La descomposici√≥n QR proporciona una soluci√≥n estable incluso cuando las Ecuaciones Normales fallan o son imprecisas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Ejercicios Guiados con Scaffolding (8+)\n",
    "Rellena las partes marcadas con `# COMPLETAR` para afianzar tu comprensi√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 1: Un Paso de Gram-Schmidt ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS\n",
    "v1 = np.array([1, 1, 0])\n",
    "v2 = np.array([1, 3, 1])\n",
    "\n",
    "# Nuestro primer vector ortogonal es v1.\n",
    "u1 = v1\n",
    "\n",
    "# TODO 1: Calcula la proyecci√≥n de v2 sobre u1.\n",
    "proj_v2_on_u1 = # COMPLETAR\n",
    "\n",
    "# TODO 2: Calcula el segundo vector ortogonal, u2, restando la proyecci√≥n de v2.\n",
    "u2 = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "assert np.allclose(proj_v2_on_u1, np.array([2, 2, 0]))\n",
    "assert np.isclose(u1 @ u2, 0), \"Los vectores u1 y u2 no son ortogonales.\"\n",
    "print(\"‚úÖ ¬°Paso de Gram-Schmidt completado con √©xito!\")\n",
    "print(f\"El componente de v2 ortogonal a v1 es: {u2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 2: Normalizaci√≥n ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS: El vector u2 del ejercicio anterior.\n",
    "u2 = np.array([-1, 1, 1])\n",
    "\n",
    "# TODO: Normaliza el vector u2 (div√≠delo por su norma L2).\n",
    "e2 = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "assert np.isclose(np.linalg.norm(e2), 1.0), \"El vector no tiene norma 1.\"\n",
    "print(\"‚úÖ ¬°Vector normalizado correctamente!\")\n",
    "print(f\"Vector unitario e2: {np.round(e2, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 3: Realizar la Descomposici√≥n QR ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS\n",
    "A = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "\n",
    "# TODO: Usa np.linalg.qr() para descomponer A en Q y R.\n",
    "Q, R = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "assert Q.shape == (3, 2) and R.shape == (2, 2), \"Las formas de Q y R son incorrectas.\"\n",
    "assert np.allclose(Q.T @ Q, np.identity(2)), \"Las columnas de Q no son ortonormales.\"\n",
    "assert np.allclose(A, Q @ R), \"La reconstrucci√≥n Q@R no es igual a A.\"\n",
    "print(\"‚úÖ ¬°Descomposici√≥n QR exitosa!\")\n",
    "print(f\"Matriz Q (columnas ortonormales):\\n{np.round(Q, 3)}\")\n",
    "print(f\"\\nMatriz R (triangular superior):\\n{np.round(R, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === EJERCICIO GUIADO 4: Resolver M√≠nimos Cuadrados con QR ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATOS\n",
    "X = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "y = np.array([1, 2, 2])\n",
    "\n",
    "# Ya tenemos Q y R de X del ejercicio anterior.\n",
    "Q, R = np.linalg.qr(X)\n",
    "\n",
    "# El problema a resolver es R¬∑Œ≤ = Q·µÄ¬∑y\n",
    "\n",
    "# TODO 1: Calcula el lado derecho de la ecuaci√≥n, Q·µÄ¬∑y.\n",
    "QTy = # COMPLETAR\n",
    "\n",
    "# TODO 2: Resuelve el sistema triangular para encontrar beta.\n",
    "beta_hat_qr = # COMPLETAR\n",
    "\n",
    "# VERIFICACI√ìN\n",
    "beta_hat_norm = np.linalg.solve(X.T @ X, X.T @ y)\n",
    "assert np.allclose(beta_hat_qr, beta_hat_norm)\n",
    "print(\"‚úÖ ¬°Sistema resuelto con QR!\")\n",
    "print(f\"Œ≤_hat = {np.round(beta_hat_qr, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# 5. Banco de Ejercicios Pr√°cticos (30+)\n",
    "Ahora te toca a ti. Resuelve estos ejercicios para consolidar tu conocimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte A: Estabilidad y Gram-Schmidt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A1 (üü¢ F√°cil):** Calcula el n√∫mero de condici√≥n de $A = \\begin{pmatrix} 1 & 2 \\\\ 3 & 4 \\end{pmatrix}$ y de $A^TA$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A2 (üü¢ F√°cil):** Aplica el primer paso de Gram-Schmidt (encontrar $\\vec{u_2}$) a los vectores $\\vec{v_1} = [1, 1]$ y $\\vec{v_2} = [0, 2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A3 (üü° Medio):** Completa el proceso de Gram-Schmidt para los vectores del ejercicio A2 para encontrar una base ortonormal $\\{\\vec{e_1}, \\vec{e_2}\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A4 (üî¥ Reto):** Aplica el proceso de Gram-Schmidt a los 3 vectores: $\\vec{v_1}=[1,1,0], \\vec{v_2}=[1,0,1], \\vec{v_3}=[0,1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte B: Descomposici√≥n QR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B1 (üü¢ F√°cil):** Calcula la descomposici√≥n QR de la matriz $A = \\begin{pmatrix} 1 & 2 \\\\ 0 & 3 \\end{pmatrix}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B2 (üü¢ F√°cil):** Verifica que para la matriz Q del ejercicio B1, se cumple que $Q^T Q$ es (aproximadamente) la matriz identidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B3 (üü° Medio):** Usando `datos_estudiantes`, construye la matriz de dise√±o $X$ y calcula su descomposici√≥n QR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B4 (üî¥ Reto):** Resuelve el problema de regresi√≥n del **Hilo Conductor** usando la Descomposici√≥n QR. Los pasos son:\n",
    "1. Construye la matriz de dise√±o `X` y el vector `y`.\n",
    "2. Calcula `Q, R = np.linalg.qr(X)`.\n",
    "3. Calcula `Qty = Q.T @ y`.\n",
    "4. Resuelve el sistema triangular `R @ beta = Qty` para `beta` usando `np.linalg.solve`.\n",
    "5. Compara los coeficientes con los obtenidos con las Ecuaciones Normales en el notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Mini-Quiz de Autoevaluaci√≥n\n",
    "\n",
    "*Responde estas preguntas para verificar tu comprensi√≥n.*\n",
    "\n",
    "1. ¬øPor qu√© es problem√°tico usar las Ecuaciones Normales cuando una matriz tiene un alto n√∫mero de condici√≥n?\n",
    "2. ¬øQu√© propiedad clave tienen las columnas de la matriz Q en una descomposici√≥n QR?\n",
    "3. ¬øQu√© algoritmo te√≥rico es la base de la descomposici√≥n QR?\n",
    "4. Al resolver $R\\hat{\\beta} = Q^T\\vec{y}$, ¬øpor qu√© es computacionalmente \"f√°cil\" encontrar $\\hat{\\beta}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "Has aprendido sobre la importancia de la estabilidad num√©rica y c√≥mo la ortogonalizaci√≥n nos proporciona m√©todos m√°s robustos para resolver problemas de la vida real. Este es el est√°ndar de oro para resolver problemas de m√≠nimos cuadrados en software profesional.\n",
    "\n",
    "- En el notebook **`1.1.5.1_Descomposicion_de_Valor_Singular_SVD.ipynb`**, exploraremos la SVD, la \"navaja suiza\" de las descomposiciones matriciales. Es el m√©todo m√°s robusto y general de todos, capaz de resolver sistemas de m√≠nimos cuadrados incluso cuando las columnas de X son linealmente dependientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
